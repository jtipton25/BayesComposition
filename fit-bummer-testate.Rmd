---
title: "Full Testate Caribou and Hole Bog Reconstructions"
author: "John Tipton"
date: "6/8/2017"
output: html_document
---


```{r, warning=FALSE, message=FALSE}
set.seed(11)
library(BayesComposition)
library(knitr)
library(ggplot2)
library(gjam)
library(rioja)
library(rstan)
library(parallel)
N <- 500
N_pred <- 25
d <- 4
n_knots <- 30
```

# Load Testate Data and R code - Full Data
```{r readData, echo=FALSE, include=FALSE, eval=TRUE, results='hide'}
raw_data <- read.csv(file="~/testate/data/North American Raw Testate - Paleon 2017-Sheet1.csv", 
                     skip=6)

y <- raw_data[, 12:85]
X <- raw_data$WTD..cm.

## join species

source("~/testate/data/join-testate.R")

## remove zeros
no_obs <- which(apply(y, 2, sum) == 0)

## down to 47 species
y <- y[, -no_obs]

## Subset rare species
sum(y)
y <- y[, apply(y, 2, sum) > 500]
# y <- y[, colSums(y) > 100]

## remove the censored observations with X == 50
y <- y[- which(X == 50), ]
X <- X[- which(X == 50)]


mean_X <- mean(X)
sd_X <- sd(X)
N <- nrow(y)

N <- dim(y)[1]
d <- dim(y)[2]

## transform the data to percentages for use in transfer function models
y_prop <- y
for (i in 1:N) {
  y_prop[i, ] <- y_prop[i, ] / sum(y_prop[i, ])
}

X_mean <- mean(X)
X_sd <- sd(X)
X_center <- (X-X_mean) / X_sd
```


```{r}
testatePlotData <- data.frame(species=as.factor(rep(colnames(y), each=N)),
                              Count=c(as.matrix(y_prop)), 
                              Wetness=rep(X, times=dim(y)[2]))

ggplot(testatePlotData, aes(x=Wetness, y=Count, color=species, group=species)) +
  geom_point(alpha=0.25) +
  # geom_line(stat="smooth", method="loess", aes(y=Count, x=Wetness),
  #           alpha=0.5, lwd=1.25) +
  theme(legend.position="none") + ggtitle("Testate Composition vs. Water Table Depth") + 
  labs(x="Water Table Depth", y="Composition") + 
  theme(plot.title=element_text(size=24, face="bold", hjust=0.5)) + 
  theme(axis.text.x = element_text(size = 22), 
        axis.text.y = element_text(size = 22),
        axis.title.x = element_text(size = 22), 
        axis.title.y = element_text(size = 22))
```


# Fit model

```{r stan-model}
if (file.exists("~/BayesComposition/mvgp-test/fit-bummer-stan.RData")) {
  ## Load MCMC run
  load("~/BayesComposition/mvgp-test/fit-bummer-stan.RData")
} else {
  ## Long running MCMC 
  library(rstan)
  n_mcmc <- 500
  rstan_options(auto_write = TRUE)
  options(mc.cores = parallel::detectCores())
  
  dat=list(N=N, d=d, X=X_center, y=matrix(y, N, d))
  
  init_fun <- function() { list(
    a=runif(d, 1, 10), 
    mu=rnorm(d, 0, 1),
    sigma2=runif(d, 1, 5), 
    alpha=matrix(runif(N*d, 1, 5), N, d)) } 
  
  fit = stan(file="~/BayesComposition/bummer-dm.stan", iter=n_mcmc,
             verbose=FALSE, data=dat, chains=4, init=init_fun,
             control=list(adapt_delta=0.99, stepsize=0.01, max_treedepth=15))
  save(fit, file="~/BayesComposition/mvgp-test/fit-bummer-stan.RData")
}
```


```{r}
# print(fit)
library(bayesplot)
## Check Rhat convergence diagnostics
layout(matrix(1:6, 3, 2))
hist(rhat(fit, pars=c("a", "mu", "sigma2", "alpha")),
     main="All parameters")
hist(rhat(fit, pars=c("a")), main="a")
hist(rhat(fit, pars=c("mu")), main="mu")
hist(rhat(fit, pars=c("sigma2")), main="sigma2")
hist(rhat(fit, pars=c("alpha")), main="alpha")
```



```{r}
## extract samples
e = rstan::extract(fit, permuted = TRUE)

library(mcmcplots)
s <-  mcmc.list(lapply(1:ncol(fit), function(x) mcmc(as.array(fit)[, x, ])))

if (!dir.exists("~/BayesComposition/mvgp-test/stan-bummer-diagnostics")) {
  dir.create("~/BayesComposition/mvgp-test/stan-bummer-diagnostics")
}
## disable the cat function to prevent RMarkdown output
invisible(capture.output(
  mcmcplot(s, parms=c("mu", "sigma2", "alpha"), 
         dir="~/BayesComposition/mvgp-test/stan-bummer-diagnostics",
         filename="stan-bummer-diagnostics", extension="html", random=20)))

```


```{r}
layout(matrix(1:3, 3, 1))
matplot(e$a, type='l')
matplot(e$mu, type='l')
matplot(e$sigma2, type='l')
```


## Plot the model fit
```{r}
p_alpha <- apply(e$alpha, c(2,3), mean)
for (i in 1:N) {
  p_alpha[i, ] <- p_alpha[i, ] / sum(p_alpha[i, ])
}
testateFitData <- data.frame(species=as.factor(rep(colnames(y), each=N)),
                              Count=c(as.matrix(y_prop)), 
                              Wetness=rep(X, times=dim(y)[2]), 
                             p_alpha=c(p_alpha))

ggplot(testateFitData, aes(x=Wetness, y=Count, color=species, group=species)) +
  geom_point(alpha=0.25) +
  # geom_line(stat="smooth", method="loess", aes(y=Count, x=Wetness),
  #           alpha=0.5, lwd=1.25) +
  theme(legend.position="none") + ggtitle("Testate Composition vs. Water Table Depth") + 
  labs(x="Water Table Depth", y="Composition") + 
  theme(plot.title=element_text(size=24, face="bold", hjust=0.5)) + 
  theme(axis.text.x = element_text(size = 22), 
        axis.text.y = element_text(size = 22),
        axis.title.x = element_text(size = 22), 
        axis.title.y = element_text(size = 22)) +
  geom_line(aes(y=p_alpha, x=Wetness, color=species)) + 
  facet_wrap(~species, ncol=6)
```


## Composition sampling for predicting missing X

```{r}
ddirmult <- function(yy, alpha) {
  sum_y <- sum(yy)
  return(exp(lgamma(apply(alpha, 1, sum)) - lgamma(sum_y + apply(alpha, 1, sum)) +
                   apply(lgamma(t(yy + t(alpha))), 1, sum) - apply(lgamma(alpha), 1, sum)))
}

n_iter <- 3 * n_mcmc / 2
n_grid <- 1000
mu_X <- mean(X[1:N_obs])
s_X <- sd(X[1:N_obs])
X_post <- matrix(0, n_iter, N-N_obs)
X_grid <- seq(from=min(X)-1.25*sd(X), to=max(X)+1.25*sd(X), length=n_grid)
alpha_pred <- array(0, dim=c(n_iter, n_grid, d))

for (k in 1:n_iter) {
  if (k %% 10 == 0) {
    message("Iteration ", k, " out of ", n_iter)
  }
  for (ii in 1:n_grid) {
    alpha_pred[k, ii, ] <- e$a[k, ] * exp( - pow(e$mu[k, ] - X_grid[ii], 2) / e$sigma2[k, ])
    }
  for (i in (N_obs+1):N) {
    pis <- ddirmult(y[i, ], alpha_pred[k, , ]) * dnorm(X_grid, mu_X, s_X)
    pis <- pis / sum(pis)
    X_post[k, i-N_obs] <- sample(X_grid, size=1, replace=FALSE, prob=pis)
  }
}    
```


```{r}
layout(matrix(1:9, 3, 3))
hist(X_post[, 1])
abline(v=X[N_obs + 1], col='red')
hist(X_post[, 2])
abline(v=X[N_obs + 2], col='red')
hist(X_post[, 3])
abline(v=X[N_obs + 3], col='red')
hist(X_post[, 4])
abline(v=X[N_obs + 4], col='red')
hist(X_post[, 5])
abline(v=X[N_obs + 5], col='red')
hist(X_post[, 6])
abline(v=X[N_obs + 6], col='red')
hist(X_post[, 7])
abline(v=X[N_obs + 7], col='red')
hist(X_post[, 8])
abline(v=X[N_obs + 8], col='red')
hist(X_post[, 9])
abline(v=X[N_obs + 9], col='red')
```


```{r}
layout(matrix(1:3, 3, 1))
idx <- order(X)

layout(matrix(1, 1, 1))
matplot(apply(X_post, 2, mean), type='l',
        ylim=c(-5, 5))
matplot(apply(X_post, 2, quantile, prob = 0.025), 
        type='l', add=TRUE, lty=2)
matplot(apply(X_post, 2, quantile, prob = 0.975), 
        type='l', add=TRUE, lty=2)
lines(X[(N_obs+1):N], col = 'red')
```


```{r}
idx_X <- order(X[(N_obs+1):N])
n_samples <- dim(X_post)[1]
sim.df <- data.frame(covariate=c(X_post[, idx_X]), 
                     observation=factor(rep((1:(N-N_obs)), each=n_samples)),
                     truth=rep(X[(N_obs+1):N][idx_X], each=n_samples))
## violin version of plot
##  only add observation ticks every 10 observations
ggplot(sim.df, aes(observation, covariate)) +
  geom_violin(position="identity") + 
  geom_point(aes(observation, truth), color="red") + 
  scale_x_discrete(breaks=seq(5, 50, 5))
```























```{r}
## extract posterior samples
samples <- extract_compositional_samples(out)
alpha_post <- samples$alpha
beta_post <- samples$beta
```





```{r}
Rhat <- make_gelman_rubin(out)
layout(matrix(1:3, 3, 1))
# hist(Rhat[grepl("alpha=", names(Rhat))], main = "Rhat for alpha")
hist(Rhat[grepl("beta", names(Rhat))], main = "Rhat for beta")
hist(Rhat, main="All parameters")
Rhat[!is.finite(Rhat)] <- NA
max(unlist(na.omit(Rhat)))
```

<!-- ```{r, eval=TRUE} -->
<!-- ##  -->
<!-- ## Posterior plots -->
<!-- ## -->

<!-- layout(matrix(1:4, 2, 2)) -->
<!-- matplot(beta_post[, , 1], type='l') -->
<!-- abline(h=dat$beta[, 1], col='red', lwd=2) -->
<!-- matplot(beta_post[, , 2], type='l') -->
<!-- abline(h=dat$beta[, 2], col='red', lwd=2) -->
<!-- matplot(beta_post[, , 3], type='l') -->
<!-- abline(h=dat$beta[, 3], col='red', lwd=2) -->
<!-- matplot(beta_post[, , 4], type='l') -->
<!-- abline(h=dat$beta[, 4], col='red', lwd=2) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- layout(matrix(1:4, 2, 2)) -->
<!-- matplot(alpha_post[, 1, ], type='l') -->
<!-- abline(h=dat$alpha[1, ]) -->
<!-- matplot(alpha_post[, 2, ], type='l') -->
<!-- abline(h=dat$alpha[2, ]) -->
<!-- matplot(alpha_post[, 3, ], type='l') -->
<!-- abline(h=dat$alpha[3, ]) -->
<!-- matplot(alpha_post[, 4, ], type='l') -->
<!-- abline(h=dat$alpha[4, ]) -->
<!-- ``` -->

```{r}
alpha_post_mean <- apply(alpha_post, c(2, 3), mean)
## force the sum to one constraint
p_alpha_post_mean <- alpha_post_mean
for (i in 1:N) {
  p_alpha_post_mean[i, ] <- p_alpha_post_mean[i, ] / sum(p_alpha_post_mean[i, ])
}

y_percentages <- y
for (i in 1:N) {
  y_percentages[i, ] <- y_percentages[i, ] / sum(y_percentages[i, ])
}

fitPlotData <- data.frame(species=as.factor(rep(1:d, each=N)), 
                          count=c(y_percentages), 
                          depth=rep(X, times=d), 
                          alpha=c(p_alpha_post_mean))

g1_post <- ggplot(fitPlotData, aes(x=depth, y=count, color=species, group=species)) + 
  geom_point(alpha=0.25) + theme(legend.position="none") +
  ggtitle("MVGP vs. depth") + 
  geom_line(aes(x=depth, y=alpha, col = species), fitPlotData, lwd=1.25)

g2_post <- ggplot(fitPlotData, aes(x=depth, y=count, color=species, group=species)) + 
  geom_point(alpha=0.25) + theme(legend.position="none") +
  ggtitle("MVGP vs. depth by species") + 
  geom_line(aes(x=depth, y=alpha, col = species), fitPlotData, lwd=1.25) + 
  facet_wrap( ~ species, ncol = 4)
multiplot(g1_post, g2_post, cols=2)
```

## load core for reconstruction

```{r}
##
## Reconstruction period data at Hole Bog
##

fileToLoad <- '~/testate/data/Hole Bog 2005 Core, raw data.csv'
n = max(count.fields(fileToLoad, sep=","), na.rm=TRUE)
xx = readLines(fileToLoad)
xx = xx[-c(1:6, 47:56)]

.splitvar = function(x, sep, n) {
  var = unlist(strsplit(x, split=","))
  length(var) = n
  return(var)
}

xx = do.call(cbind, lapply(xx, .splitvar, sep=",", n=n))
xx = apply(xx, 1, paste, collapse=",") 
y_recon = read.csv(text=xx, sep=",", header=TRUE)

##  processing data to have names first 3 letters of genus and species
genus_hole <- tolower(substr(names(y_recon), 1, 3))
species_hole <- substr(sub(".*\\.", "", sub("\\.catinus", "", sub("\\.minor", "", sub("\\.\\.", "", sub("\\.type", "", names(y_recon)))))), 1, 3)
names(y_recon) <- paste(genus_hole, species_hole, sep="")


source("~/testate/data/join-testate-caribou.R")

##
## align names between data sets
## get expert input here!!
## We are removing many species
##

N_recon_full <- sum(y_recon)

idx1 <- colnames(y) %in% names(y_recon)
# names(y_recon)[!idx1]
# names(y_cal)[!idx2]

## add in any species in calibation data not in reconstruction data
for (i in colnames(y)[!idx1]){
  y_recon[, i] <- rep(0, dim(y_recon)[1])
}

idx2 <- names(y_recon) %in% colnames(y)
## remove species in reconstruction data not in calibration data
for (i in names(y_recon)[!idx2]){
  y_recon[, i] <- NULL
}

y_recon <- y_recon[, order(colnames(y_recon))]

## check the names and orderings
all.equal(colnames(y), colnames(y_recon))

## Note: we are reducing the testate counts by about 25%...
N_recon_reduced <- sum(y_recon)
N_recon_full - N_recon_reduced


```


```{r}
pred <- predict_compositional_data(as.matrix(y_recon), X, 
                           params=params, samples=samples, 
                           progress_directory=progress_directory,
                           progress_file = "DM-predict.txt")
```





```{r}
n_samples <- length(pred$X[, 1])
N_pred <- length(pred$X[1, ])
X_ci <- apply(pred$X, 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ]

hole.df <- data.frame(
  Covariate=c(X_ci),
  Observation=factor(rep((1:N_pred), each=n_samples*0.95))
)

ggplot(hole.df, aes(Observation, Covariate)) +
  geom_violin(position="identity") +
  scale_x_discrete(breaks=seq(5, 25, 5)) + 
  labs(x="Observation", y="Unobserved July Temperature")
```






```{r, message=FALSE, include=FALSE, cache=TRUE}
y_prop <- y
y_recon_prop <- y_recon
for (i in 1:N) {
  y_prop[i, ] <- y_prop[i, ] / sum(y_prop[i, ])
}
for (i in 1:N_pred) {
  y_recon_prop[i, ] <- y_recon_prop[i, ] / sum(y_recon_prop[i, ])
}

## WA reconstruction - subset to deal with all zero occurrence species
zeros_idx <- which(colSums(y_prop) == 0)
if (length(zeros_idx) > 0) {
  modWA <- rioja::WA(y_prop[, - zeros_idx], X)
  predWA <- predict(modWA, y_recon_prop[, - zeros_idx], sse=TRUE, nboot=1000)
} else {
  ## no data to subset
  modWA <- rioja::WA(y_prop, X)
  predWA <- predict(modWA, y_recon_prop, sse=TRUE, nboot=1000)      
}

pred_mu_WA <- predWA$fit[, 1]
pred_sd_WA <- sqrt(predWA$v1.boot[, 1])

## MLRC reconstruction - subset to deal with all zero occurrence species
zeros_idx <- which(colSums(y_prop) == 0)
if (length(zeros_idx) > 0) {
  modMLRC <- rioja::MLRC(y_prop[, - zeros_idx], X)
  predMLRC <- predict(modMLRC, y_recon_prop[, - zeros_idx],
                      sse=TRUE, nboot=1000)
} else {
  modMLRC <- rioja::MLRC(y_prop, X)
  predMLRC <- predict(modMLRC, y_recon_prop, sse=TRUE, nboot=1000)
}

pred_mu_MLRC <- predMLRC$fit[, 1]
pred_sd_MLRC <- sqrt(predMLRC$v1.boot[, 1])

## Modern analogue technique
modMAT <- mat(y, X)
predMAT <- predict(modMAT, y_recon, bootstrap=TRUE, n.boot=1000)

pred_mu_MAT <- apply(predMAT$predictions$model$predicted, 2, mean)
pred_sd_MAT <- apply(predMAT$predictions$model$predicted, 2, sd)  

## GJAM model fit
idx_hold <- (N+1):(N+N_pred)
Xdf <- data.frame(x=c(X, rep(NA, N_pred)))
Xdf$x[idx_hold] <- NA
ydf <- data.frame(as.matrix(rbind(y, y_recon)))
colnames(ydf) <- paste("y", 1:dim(y)[2], sep="")
ml <- list(ng = 5000, burnin = 500, typeNames = rep("CC", dim(y)[2]),
           PREDICTX=TRUE)
## fit second order polynomial model
out <- gjam(~ x + I(x^2), Xdf, ydf, ml)

pred_mu_GJAM  <- out$prediction$xpredMu[idx_hold, 2]        #inverse prediction of x
pred_sd_GJAM  <- out$prediction$xpredSd[idx_hold, 2]

## Random Forest
library(randomForest)
train <- data.frame(y=X, as.matrix(y))
test <- data.frame(y_recon)
n_samples <- length(pred$X[, 1])
rf <- randomForest(y ~ ., data = train, ntree=n_samples)
preds_rf <- predict(rf, test, predict.all=TRUE)$individual


```



```{r}
n_samples <- length(pred$X[, 1])
N_pred <- length(pred$X[1, ])

preds_WA <- matrix(0, n_samples, N_pred)
preds_MLRC <- matrix(0, n_samples, N_pred)
preds_MAT <- matrix(0, n_samples, N_pred)
# preds_GJAM <- matrix(0, n_samples, d)
for (i in 1:N_pred) {
  preds_WA[, i] <- rnorm(n_samples, pred_mu_WA[i], pred_sd_WA[i])
  preds_MLRC[, i] <- rnorm(n_samples, pred_mu_MLRC[i], pred_sd_MLRC[i])
  preds_MAT[, i] <- rnorm(n_samples, pred_mu_MAT[i], pred_sd_MAT[i])
  # preds_GJAM[, j] <- rnorm(n_samples, pred_mu_GJAM, pred_sd_GJAM)
}
X_ci <- rbind(apply(pred$X, 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ], 
          apply(preds_WA, 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ], 
          apply(preds_MLRC, 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ], 
          apply(preds_MAT, 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ], 
          apply(preds_rf, 1, sort)[(0.025*n_samples+1):(0.975*n_samples), ])
          # apply(preds_GJAM, 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ])
          
hole.df <- data.frame(
  Covariate=c(X_ci),
  Observation=factor(rep((1:N_pred), each=5*n_samples*0.95)), 
  Model=rep(c("MVGP", "WA", "MLRC", "MAT", "RF"), each=n_samples*0.95)
)

ggplot(hole.df, aes(Observation, Covariate, color=Model)) +
  geom_violin(position="dodge") +
  scale_x_discrete(breaks=seq(5, 25, 5)) + 
  labs(x="Observation", y="Unobserved Water Depth") +
  facet_wrap(~ Model, ncol=2) + 
  stat_summary(fun.y = mean, geom = "line", aes(Observation, Covariate, group=Model))

```



```{r}
ggplot(hole.df, aes(Observation, Covariate, color=Model)) +
  scale_x_discrete(breaks=seq(5, 25, 5)) + 
  labs(x="Observation", y="Unobserved Water Depth") +
  stat_summary(fun.y = mean, geom = "line", aes(Observation, Covariate, group=Model)) + 
    stat_summary(fun.ymin = function(z) {quantile(z, 0.025)},
                 fun.ymax = function(z) {quantile(z, 0.975)},
                 geom = "ribbon", aes(Observation, Covariate,
                                      group=Model, color=Model, fill=Model), alpha=0.25) +
  ylim(-10, 60)
```


```{r}
ggplot(hole.df, aes(Observation, Covariate, color=Model)) +
  scale_x_discrete(breaks=seq(5, 25, 5)) + 
  labs(x="Observation", y="Unobserved Water Depth") +
  stat_summary(fun.y = mean, geom = "line", aes(Observation, Covariate, group=Model)) + 
    stat_summary(fun.ymin = function(z) {quantile(z, 0.025)},
                 fun.ymax = function(z) {quantile(z, 0.975)},
                 geom = "ribbon", aes(Observation, Covariate,
                                      group=Model, color=Model, fill=Model), alpha=0.25) +
  facet_wrap(~Model, ncol=2) +
  ylim(-10, 60)
```


## Caribou bog


```{r}
# fileToLoad <- read.csv("~/Documents/connoR/Caribou/cariboucounts.csv")
fileToLoad <- read.csv("~/testate/data/rawData/cariboucounts.csv")

y_recon <- fileToLoad[,10:60]

#source("~/Documents/connoR/testate/data/join-testate-caribou.R")

N_recon_full <- sum(y_recon)

idx1 <- colnames(y) %in% names(y_recon)
# names(y_recon)[!idx1]
# names(y_cal)[!idx2]

## add in any species in calibation data not in reconstruction data
for (i in colnames(y)[!idx1]){
  y_recon[, i] <- rep(0, dim(y_recon)[1])
}

idx2 <- names(y_recon) %in% colnames(y)
## remove species in reconstruction data not in calibration data
for (i in names(y_recon)[!idx2]){
  y_recon[, i] <- NULL
}

y_recon <- y_recon[, order(colnames(y_recon))]

## check the names and orderings
all.equal(colnames(y), colnames(y_recon))

## Note: we are reducing the testate counts by about 25%...
N_recon_reduced <- sum(y_recon)
N_recon_full - N_recon_reduced



```

```{r}
pred <- predict_compositional_data(as.matrix(y_recon), X, 
                           params=params, samples=samples, 
                           progress_directory=progress_directory,
                           progress_file = "DM-predict.txt")

```

```{r}
n_samples <- length(pred$X[, 1])
N_pred <- length(pred$X[1, ])
X_ci <- apply(pred$X, 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ]

caribou.df <- data.frame(
  Covariate=c(X_ci),
  Observation=factor(rep((1:N_pred), each=n_samples*0.95))
)

ggplot(caribou.df, aes(Observation, Covariate)) +
  geom_violin(position="identity") +
  scale_x_discrete(breaks=seq(5, 310, 5)) + 
  labs(x="Observation", y="Unobserved WTD")
```


```{r}
y_prop <- y
y_recon_prop <- y_recon
for (i in 1:N) {
  y_prop[i, ] <- y_prop[i, ] / sum(y_prop[i, ])
}
for (i in 1:N_pred) {
  y_recon_prop[i, ] <- y_recon_prop[i, ] / sum(y_recon_prop[i, ])
}

## WA reconstruction - subset to deal with all zero occurrence species
zeros_idx <- which(colSums(y_prop) == 0)
if (length(zeros_idx) > 0) {
  modWA <- rioja::WA(y_prop[, - zeros_idx], X)
  predWA <- predict(modWA, y_recon_prop[, - zeros_idx], sse=TRUE, nboot=1000)
} else {
  ## no data to subset
  modWA <- rioja::WA(y_prop, X)
  predWA <- predict(modWA, y_recon_prop, sse=TRUE, nboot=1000)      
}

pred_mu_WA <- predWA$fit[, 1]
pred_sd_WA <- sqrt(predWA$v1.boot[, 1])

## MLRC reconstruction - subset to deal with all zero occurrence species
zeros_idx <- which(colSums(y_prop) == 0)
if (length(zeros_idx) > 0) {
  modMLRC <- rioja::MLRC(y_prop[, - zeros_idx], X)
  predMLRC <- predict(modMLRC, y_recon_prop[, - zeros_idx],
                      sse=TRUE, nboot=1000)
} else {
  modMLRC <- rioja::MLRC(y_prop, X)
  predMLRC <- predict(modMLRC, y_recon_prop, sse=TRUE, nboot=1000)
}

pred_mu_MLRC <- predMLRC$fit[, 1]
pred_sd_MLRC <- sqrt(predMLRC$v1.boot[, 1])

## Modern analogue technique
modMAT <- mat(y, X)
predMAT <- predict(modMAT, y_recon, bootstrap=TRUE, n.boot=1000)

pred_mu_MAT <- apply(predMAT$predictions$model$predicted, 2, mean)
pred_sd_MAT <- apply(predMAT$predictions$model$predicted, 2, sd)  

## GJAM model fit
idx_hold <- (N+1):(N+N_pred)
Xdf <- data.frame(x=c(X, rep(NA, N_pred)))
Xdf$x[idx_hold] <- NA
ydf <- data.frame(as.matrix(rbind(y, y_recon)))
colnames(ydf) <- paste("y", 1:dim(y)[2], sep="")
ml <- list(ng = 5000, burnin = 500, typeNames = rep("CC", dim(y)[2]),
           PREDICTX=TRUE)
## fit second order polynomial model
# out <- gjam(~ x + I(x^2), Xdf, ydf, ml)
# 
# pred_mu_GJAM  <- out$prediction$xpredMu[idx_hold, 2]        #inverse prediction of x
# pred_sd_GJAM  <- out$prediction$xpredSd[idx_hold, 2]

## Random Forest
library(randomForest)
train <- data.frame(y=X, as.matrix(y))
test <- data.frame(y_recon)
n_samples <- length(pred$X[, 1])
rf <- randomForest(y ~ ., data = train, ntree=n_samples)
preds_rf <- predict(rf, test, predict.all=TRUE)$individual

```


```{r}
n_samples <- length(pred$X[, 1])
N_pred <- length(pred$X[1, ])

preds_WA <- matrix(0, n_samples, N_pred)
preds_MLRC <- matrix(0, n_samples, N_pred)
preds_MAT <- matrix(0, n_samples, N_pred)
# preds_GJAM <- matrix(0, n_samples, d)
for (i in 1:N_pred) {
  preds_WA[, i] <- rnorm(n_samples, pred_mu_WA[i], pred_sd_WA[i])
  preds_MLRC[, i] <- rnorm(n_samples, pred_mu_MLRC[i], pred_sd_MLRC[i])
  preds_MAT[, i] <- rnorm(n_samples, pred_mu_MAT[i], pred_sd_MAT[i])
  # preds_GJAM[, j] <- rnorm(n_samples, pred_mu_GJAM, pred_sd_GJAM)
}
X_ci <- rbind(apply(pred$X, 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ], 
          apply(preds_WA, 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ], 
          apply(preds_MLRC, 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ], 
          apply(preds_MAT, 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ], 
          apply(preds_rf, 1, sort)[(0.025*n_samples+1):(0.975*n_samples), ])
          # apply(preds_GJAM, 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ])
          
caribou.df <- data.frame(
  Covariate=c(X_ci),
  Observation=factor(rep((1:N_pred), each=5*n_samples*0.95)), 
  Model=rep(c("MVGP", "WA", "MLRC", "MAT", "RF"), each=n_samples*0.95)
)

ggplot(caribou.df, aes(Observation, Covariate, color=Model)) +
  geom_violin(position="dodge") +
  scale_x_discrete(breaks=seq(5, 310, 10)) + 
  labs(x="Observation", y="Unobserved Water Depth") +
  facet_wrap(~ Model, ncol=2) + 
  stat_summary(fun.y = mean, geom = "line", aes(Observation, Covariate, group=Model))

ggsave("caribou_recons.png")

ggplot(caribou.df, aes(Observation, Covariate, color=Model)) +
  #geom_violin(position="dodge") +
  scale_x_discrete(breaks=seq(310, 0, -10)) + 
  labs(x="Observation", y="Unobserved Water Depth") +
  facet_wrap(~ Model, ncol=2) + 
  stat_summary(fun.y = mean, geom = "line", aes(Observation, Covariate, group=Model)) +
  scale_y_reverse()
```



```{r}
ggplot(caribou.df, aes(Observation, Covariate, color=Model)) +
  labs(x="Observation", y="Unobserved Water Depth") +
  stat_summary(fun.y = mean, geom = "line", aes(Observation, Covariate, group=Model)) + 
    stat_summary(fun.ymin = function(z) {quantile(z, 0.025)},
                 fun.ymax = function(z) {quantile(z, 0.975)},
                 geom = "ribbon", aes(Observation, Covariate,
                                      group=Model, color=Model, fill=Model), alpha=0.25) +
  ylim(-10, 60)
```



```{r}
ggplot(subset(caribou.df, Model %in% c("MVGP", "WA")), aes(Observation, Covariate, color=Model)) +
  labs(x="Observation", y="Unobserved Water Depth") +
  stat_summary(fun.y = mean, geom = "line", aes(Observation, Covariate, group=Model)) + 
    # stat_summary(fun.ymin = function(z) {quantile(z, 0.025)},
    #              fun.ymax = function(z) {quantile(z, 0.975)},
    #              geom = "ribbon", aes(Observation, Covariate,
    #                                   group=Model, color=Model, fill=Model), alpha=0.25) +
  ylim(-10, 60)
```



```{r}
ggplot(caribou.df, aes(Observation, Covariate, color=Model)) + 
  labs(x="Observation", y="Unobserved Water Depth") +
  stat_summary(fun.y = mean, geom = "line", aes(Observation, Covariate, group=Model)) + 
    stat_summary(fun.ymin = function(z) {quantile(z, 0.025)},
                 fun.ymax = function(z) {quantile(z, 0.975)},
                 geom = "ribbon", aes(Observation, Covariate,
                                      group=Model, color=Model, fill=Model), alpha=0.25) +
  facet_wrap(~Model, ncol=2) +
  ylim(-10, 60)
```
