---
title: "No-analogue"
author: "John Tipton"
date: "10/17/2017"
output: html_document
---

```{r, warning=FALSE, message=FALSE}
set.seed(11)
library(BayesComposition)
library(knitr)
library(ggplot2)
library(rioja)
library(analogue)
library(here)
library(snowfall)

N <- 500
d <- 4
n_knots <- 30

```


## Booth 2008 data
```{r}
# Load Testate Data and R code - Booth 2008
raw_data <- read.csv(file="~/testate/data/North American Raw Testate - Paleon 2017-Sheet1.csv", 
                     skip=6)

## subset to Booth 2008
raw_data <- raw_data[1:378, ]
y <- raw_data[, 12:85]
X <- raw_data$WTD..cm.

## Subset to Booth 2008 data
N <- 356
N_obs <- 356
y <- y[1:356, ]
X <- X[1:356]

## join species

source("~/testate/data/join-testate-booth.R")

## remove zeros
no_obs <- which(apply(y, 2, sum) == 0)

## down to 47 species
y <- y[, -no_obs]

## Subset rare species
sum(y)
y <- y[, apply(y, 2, sum) > 500]
# y <- y[, colSums(y) > 100]

mean_X <- mean(X)
sd_X <- sd(X)
X <- (X - mean_X) / sd_X
N <- nrow(y)

N <- dim(y)[1]
d <- dim(y)[2]

## transform the data to percentages for use in transfer function models
y_prop <- y
for (i in 1:N) {
  y_prop[i, ] <- y_prop[i, ] / sum(y_prop[i, ])
}
```


```{r}
testatePlotData <- data.frame(species=as.factor(rep(colnames(y), each=N)),
                              Count=c(as.matrix(y_prop)), 
                              Wetness=rep(X, times=dim(y)[2]))

ggplot(testatePlotData, aes(x=Wetness, y=Count, color=species, group=species)) +
  geom_point(alpha=0.25) +
  # geom_line(stat="smooth", method="loess", aes(y=Count, x=Wetness),
  #           alpha=0.5, lwd=1.25) +
  theme(legend.position="none") + ggtitle("Testate Composition vs. Water Table Depth") + 
  labs(x="Water Table Depth", y="Composition") + 
  theme(plot.title=element_text(size=24, face="bold", hjust=0.5)) + 
  theme(axis.text.x = element_text(size = 22), 
        axis.text.y = element_text(size = 22),
        axis.title.x = element_text(size = 22), 
        axis.title.y = element_text(size = 22))
```

## Simulate a "no-analog" situation
```{r}
library(dplyr)
modMATDist <- MAT(y_prop, X, k=20, lean=FALSE)

mod_dists <- tibble(set = "mod", distance = as.vector(modMATDist$dist.n))

## 0.575 cut-off chosen so the validation set is approximately the same size
## as one of the 12-fold cross-validation sets
analog_idx <- which(apply(modMATDist$dist.n, 1, min)  > 0.275)
# length(analog_idx) ## 32
# 356/12  ## 30

y_train <- y[-analog_idx, ]
y_test <- y[analog_idx, ]
X_train <- X[-analog_idx]
X_test <- X[analog_idx]
y_train_prop <- y_train
for (i in 1:nrow(y_train)) {
  y_train_prop[i, ] <- y_train_prop[i, ] / sum(y_train_prop[i, ])
}
y_test_prop <- y_test
for (i in 1:nrow(y_test)) {
  y_test_prop[i, ] <- y_test_prop[i, ] / sum(y_test_prop[i, ])
}
N_pred <- dim(y_test)[1]

modMATDistTrain <- MAT(y_train_prop, X, k=20, lean=FALSE)
predMATDist <- predict(modMATDistTrain, y_test_prop, k=20, sse=TRUE, n.boot=1000)
mod_dists <- tibble(set = "mod", distance = as.vector(modMATDistTrain$dist.n))
pred_dists <- tibble(set = "pred", distance = as.vector(predMATDist$dist.n))

MAT_dists <- bind_rows(mod_dists, pred_dists)


MAT_dists_plot <- ggplot(MAT_dists, aes(distance, fill=set)) +
  geom_density(alpha=0.7, adjust=1, colour="grey50") + 
  labs(x="square chord distance") + 
  scale_fill_discrete(name=element_blank(), breaks=c("mod", "pred"),
                      labels=c("Training Set", "Reconstruction Set")) +
  theme_bw() + theme(legend.position = "bottom")
MAT_dists_plot

```


```{r}
analogPlotData <- data.frame(
  species = as.factor(rep(colnames(y), each=length(X_train))),
  Count   = c(as.matrix(y_train_prop)), 
  Wetness = rep(X_train, times=dim(y_train_prop)[2]))

noanalogPlotData <- data.frame(
  species = as.factor(rep(colnames(y), each=length(X_test))),
  Count   = c(as.matrix(y_test_prop)), 
  Wetness = rep(X_test, times=dim(y_test_prop)[2]))

gp1 <- ggplot(analogPlotData, aes(x=Wetness, y=Count, color=species, group=species)) +
  geom_point(alpha=0.25) +
  # geom_line(stat="smooth", method="loess", aes(y=Count, x=Wetness),
  #           alpha=0.5, lwd=1.25) +
  theme(legend.position="none") + ggtitle("Analog Training Data") + 
  labs(x="Water Table Depth", y="Composition") + 
  theme(plot.title=element_text(size=24, face="bold", hjust=0.5)) + 
  theme(axis.text.x = element_text(size = 22), 
        axis.text.y = element_text(size = 22),
        axis.title.x = element_text(size = 22), 
        axis.title.y = element_text(size = 22))
gp2 <- ggplot(noanalogPlotData, 
              aes(x=Wetness, y=Count, color=species, group=species)) +
  geom_point(alpha=0.25) +
  # geom_line(stat="smooth", method="loess", aes(y=Count, x=Wetness),
  #           alpha=0.5, lwd=1.25) +
  theme(legend.position="none") + ggtitle("No Analog Training Data") + 
  labs(x="Water Table Depth", y="Composition") + 
  theme(plot.title=element_text(size=24, face="bold", hjust=0.5)) + 
  theme(axis.text.x = element_text(size = 22), 
        axis.text.y = element_text(size = 22),
        axis.title.x = element_text(size = 22), 
        axis.title.y = element_text(size = 22))
multiplot(gp1, gp2, cols=1)
```


```{r}
y <- as.matrix(y)
# mean_X <- mean(X)
# sd_X <- sd(X)
# X <- (X - mean_X) / sd_X
X_knots <- seq(min(X, na.rm=TRUE)-1.25*sd(X, na.rm=TRUE), 
               max(X, na.rm=TRUE)+1.25*sd(X, na.rm=TRUE), length=n_knots)

params <- list(n_adapt=25000, n_mcmc=50000, n_thin=50, 
               X_knots=X_knots, message=500)

save_directory <- "./mvgp-test/"
save_file <- paste0("dm-testate-no-analog-appendix.RData")
progress_directory <- "./mvgp-test/"
progress_file <- paste0("mvgp-dm-testate-no-analog-appendix.txt")
```


```{r}
## Fit no-analog using B-spline model
if (file.exists(paste0(save_directory, save_file))) {
  ## load mcmc
  load(file=paste0(save_directory, save_file))
} else {
  
  ## potentially long running MCMC code
  parallelChains <- function (n_chains) {
    Rcpp::sourceCpp('~/mvgp/mcmc/mcmc-dirichlet-multinomial-mvgp.cpp')
    out <- coda::mcmc(mcmcRcpp(as.matrix(y_train), X_train, as.matrix(y_test), 
                               params, n_chain=n_chains, 
                               file_name=here(progress_directory,
                                              progress_file)))
  }
  
  ## Initalize multicore
  sfInit(parallel=TRUE, cpus=4)
  sfClusterSetupRNG()
  sfExport("y_train", "X_train", "y_test", "params", "progress_directory", 
           "progress_file")
  sfLibrary(coda)
  sfLibrary(here)
  
  ## create temporary progress file  
  file.create(here(progress_directory, progress_file))
  
  ## run MCMC
  out <- sfLapply(1:4, parallelChains)
  
  sfStop()
  
  save(out, file=paste0(save_directory, save_file))
  
  # save(out, file=paste0(save_directory, save_file))
  
  Rhat <- make_gelman_rubin(out)
  png(file=here("mvgp-test", "diagnostics",
                paste0("Rhat-no-analog-appendix.png")),
      width=6, height=6, units="in", res=400)
  layout(matrix(1:9, 3, 3))
  hist(Rhat[grepl("eta", names(Rhat))], main = "Rhat for eta")
  hist(Rhat[grepl("mu", names(Rhat))], main = "Rhat for mu")
  hist(Rhat[grepl("alpha", names(Rhat))], main = "Rhat for alpha")
  hist(Rhat[grepl("zeta", names(Rhat))], main = "Rhat for zeta")
  hist(Rhat[grepl("tau2", names(Rhat))], main = "Rhat for tau2")
  hist(Rhat[grepl("X", names(Rhat))], main = "Rhat for X")
  hist(Rhat[grepl("xi", names(Rhat))], main = "Rhat for xi")
  hist(Rhat[grepl("phi", names(Rhat))], main = "Rhat for phi")
  hist(Rhat, main="All parameters")
  dev.off()
}
```


```{r}
## extract posterior samples
samples <- convert_to_coda(out)

n_chains <- 4
n_save <- dim(samples[[1]])[1] 
n_samples <- n_save*n_chains

mu_post <- matrix(0, n_samples, d)
eta_star_post <- array(0, dim=c(n_samples, n_knots, d))
zeta_post <-  array(0, dim=c(n_samples, N-N_pred, d))
alpha_post <-  array(0, dim=c(n_samples, N-N_pred, d))
zeta_pred_post <-  array(0, dim=c(n_samples, N_pred, d))
alpha_pred_post <-  array(0, dim=c(n_samples, N_pred, d))
phi_post <- rep(0,  n_samples)
tau2_post <- matrix(0,  n_samples, d)
X_pred <- matrix(0,  n_samples, N_pred)
xi_post <- array(0,  dim=c(n_samples, choose(d, 2)))
R_post <- array(0, dim=c(n_samples, d, d))

for(i in 1:n_chains){
  mu_post[1:n_save + (i-1)*n_save, ] <- out[[i]]$mu
  eta_star_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$eta_star
  zeta_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$zeta
  alpha_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$alpha
  zeta_pred_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$zeta_pred
  alpha_pred_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$alpha_pred
  phi_post[1:n_save + (i-1)*n_save] <- out[[i]]$phi
  tau2_post[1:n_save + (i-1)*n_save, ] <- out[[i]]$tau2
  X_pred[1:n_save + (i-1)*n_save, ] <- out[[i]]$X
  xi_post[1:n_save + (i-1)*n_save, ] <- out[[i]]$xi
  R_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$R
}          
```


```{r}
alpha_post_mean <- apply(alpha_post, c(2, 3), mean)
p_alpha <- alpha_post_mean

for (i in 1:length(X_train)) {
  ## normalize to sum-to-one constraint
  p_alpha[i, ] <- p_alpha[i, ] / sum(p_alpha[i, ])
}

fitPlotData <- data.frame(
  species = as.factor(rep(1:d, each=length(X_train))), 
  count = c(as.matrix(y_train_prop)), 
  depth = rep(X_train, times=d), 
  alpha = c(p_alpha))

g1_post <- ggplot(fitPlotData, aes(x=depth, y=count, color=species, group=species)) + 
  geom_point(alpha=0.25) + theme(legend.position="none") +
  ggtitle("Fitted Response vs. depth") + 
  geom_line(aes(x=depth, y=alpha, col = species), fitPlotData, lwd=1.25)

g2_post <- ggplot(fitPlotData, aes(x=depth, y=count, color=species, group=species)) + 
  geom_point(alpha=0.25) + theme(legend.position="none") +
  ggtitle("Fitted Response vs. depth by species") + 
  geom_line(aes(x=depth, y=alpha, col = species), fitPlotData, lwd=1.25) + 
  facet_wrap( ~ species, ncol = 4)
multiplot(g1_post, g2_post, cols=2)
```


```{r, message=FALSE, include=FALSE}

if (file.exists(paste0(save_directory, "other-models-no-analog-appendix.RData"))) {
  load(file=paste0(save_directory, "other-models-no-analog-appendix.RData"))
} else {
  y_train_prop <- as.matrix(y_train_prop)

  ## WA reconstruction - subset to deal with all zero occurrence species
  zeros_idx <- which(apply(y_train_prop, 2, sum) == 0)
  if (length(zeros_idx) > 0) {
    modWA <- rioja::WA(y_train_prop[, - zeros_idx], X_train)
    predWA <- predict(modWA, y_test_prop[, - zeros_idx], sse=TRUE, nboot=1000)
  } else {
    ## no data to subset
    modWA <- rioja::WA(y_train_prop, X_train)
    predWA <- predict(modWA, y_test_prop, sse=TRUE, nboot=1000)      
  }
  
  pred_mu_WA <- predWA$fit[, 1]
  pred_sd_WA <- sqrt(predWA$v1.boot[, 1]^2 + predWA$v2.boot[1]^2)
  
  ## MLRC reconstruction - subset to deal with all zero occurrence species
  zeros_idx <- which(apply(y_train_prop, 2, sum) == 0)
  if (length(zeros_idx) > 0) {
    modMLRC <- rioja::MLRC(y_train_prop[, - zeros_idx], X_train)
    predMLRC <- predict(modMLRC, y_test_prop[, - zeros_idx],
                        sse=TRUE, nboot=1000)
  } else {
    modMLRC <- rioja::MLRC(y_train_prop, X_train)
    predMLRC <- predict(modMLRC, y_test_prop, sse=TRUE, nboot=1000)
  }
  
  pred_mu_MLRC <- predMLRC$fit[, 1]
  pred_sd_MLRC <- sqrt(predMLRC$v1.boot[, 1]^2 + predMLRC$v2.boot[1]^2)
  
  ## Modern analogue technique
  modMAT <- MAT(y_train_prop, X_train, k=20, lean=FALSE)
  predMAT <- predict(modMAT, y_test_prop, k=10, sse=TRUE, n.boot=1000)
  
  pred_mu_MAT <- predMAT$fit.boot[, 2]
  pred_sd_MAT <- sqrt(predMAT$v1.boot[, 2]^2+ predMAT$v2.boot[2])
  
  ## Random Forest
  library(randomForest)
  train <- data.frame(y=X_train, as.matrix(y_train_prop))
  test <- data.frame(as.matrix(y_test_prop))
  n_samples <- 2000
  rf <- randomForest(y ~ ., data = train, ntree=n_samples)
  preds_rf <- predict(rf, test, predict.all=TRUE)$individual

  save(pred_mu_WA, pred_sd_WA, pred_mu_MLRC, pred_sd_MLRC, 
       pred_mu_MAT, pred_sd_MAT, preds_rf, 
       file= paste0(save_directory, "other-models-no-analog-appendix.RData"))
}
```
  
  
  
# Fit stan model
# Fit model

```{r stan-model-testate}
## unload snow and snowfall packages as they confilct with STAN
detach_package <- function(pkg, character.only = FALSE)
{
  if(!character.only)
  {
    pkg <- deparse(substitute(pkg))
  }
  search_item <- paste("package", pkg, sep = ":")
  while(search_item %in% search())
  {
    detach(search_item, unload = TRUE, character.only = TRUE)
  }
}
detach_package(snowfall)
detach_package(snow)
## check if snow and snowfall packages are loaded
(.packages())

# mu_X <- mean(X)
# sd_X <- sd(X)
# X_center <- (X_train-mu_X) / sd_X
X_center <- X[-analog_idx]
if (file.exists(paste0(save_directory, "bummer-no-analog-appendix.RData"))) {
  ## Load MCMC run
  load(paste0(save_directory, "bummer-no-analog-appendix.RData"))
} else {
  ## Long running MCMC
  library(rstan)
  n_mcmc <- 500
  rstan_options(auto_write = TRUE)
  options(mc.cores = parallel::detectCores())
  
  dat=list(N=length(X_center), d=dim(y_train)[2], X=X_center, 
           y=as.matrix(y_train, length(X_center), dim(y_train)[2]))
  
  init_fun <- function() { list(
    a=runif(d, 1, 10),
    mu=rnorm(d, 0, 1),
    sigma2=runif(d, 1, 5),
    alpha=matrix(runif(N*d, 1, 5), N, d)) }
  
  fit = stan(file="~/BayesComposition/bummer-dm.stan", iter=n_mcmc,
             verbose=FALSE, data=dat, chains=4, init=init_fun,
             control=list(adapt_delta=0.99, stepsize=0.01, max_treedepth=15))
  save(fit, file=paste0(save_directory, "bummer-no-analog-appendix.RData"))
}
```

### predict using stan model

```{r}

X_pred_bummer <- c()
if (file.exists(paste0(save_directory, "bummer-no-analog-predictions-appendix.RData"))) {
  load(file=paste0(save_directory, "bummer-no-analog-predictions-appendix.RData"))
} else {
  ## load the data
  load(paste0(save_directory, "bummer-no-analog-appendix.RData"))
  ## extract samples
  e = rstan::extract(fit, permuted = TRUE)
  
  ddirmult <- function(yy, alpha, log=TRUE) {
    yy <- as.numeric(yy)
    sum_y <- sum(yy)
    if (log) {
      return(lgamma(apply(alpha, 1, sum)) -
               lgamma(sum_y + apply(alpha, 1, sum)) +
               apply(lgamma(t(yy + t(alpha))), 1, sum) - 
               apply(lgamma(alpha), 1, sum))
    } else {
      return(exp(lgamma(apply(alpha, 1, sum)) - 
                   lgamma(sum_y + apply(alpha, 1, sum)) +
                   apply(lgamma(t(yy + t(alpha))), 1, sum) - 
                   apply(lgamma(alpha), 1, sum)))      
    }
  }
  n_iter <- dim(e$a)[1]
  n_grid <- 500
  N_pred <- dim(y_test)[1]
  XX_post <- matrix(0, n_iter, N_pred)
  X_grid <- seq(from=min(X_center) - 1.25*sd(X_center), 
                to=max(X_center) + 1.25*sd(X_center), length=n_grid)
  alpha_pred <- array(0, dim=c(n_iter, n_grid, d))
  
  for (k in 1:n_iter) {
    if (k %% 50 == 0) {
      message("Iteration ", k, " out of ", n_iter)
    }
    for (ii in 1:n_grid) {
      alpha_pred[k, ii, ] <- e$a[k, ] * exp( - (e$mu[k, ] - X_grid[ii])^2 / e$sigma2[k, ])
    }
    for (ii in 1:N_pred) {
      tmp <- ddirmult(y_test[ii, ], alpha_pred[k, , ], log=TRUE)
      ## correct for numeric overflow
      ## doesn't change anything because we divide by the correction factor
      pis <- exp(tmp - max(tmp)) * dnorm(X_grid, 0, 1)
      pis <- pis / sum(pis)
      XX_post[k, ii] <- sample(X_grid, size=1, replace=FALSE, prob=pis)
    }
  }
  
  ## convert to original scale
  # XX_post <- XX_post * sd_X + mu_X
  X_pred_bummer <- XX_post
  save(X_pred_bummer,
       file=paste0(save_directory, "bummer-no-analog-predictions-appendix.RData"))
}
```


## Plot results

```{r} 
layout(matrix(1:6, 2, 3))
## sort the data to be in the same order as the predictions
plot(apply(X_pred, 2, mean) ~ X_test, ylab="predicted mean", xlab="Observed", 
     main="Cross-validation of MVGP model", 
     xlim=range(X_test), ylim=c(min(X_test - 2), max(X_test + 2)))
## Notice most of the confidence intervals cover the red linear regression line 
## i.e. the 95% CI is close to 95%
segments(x0=X_test, y0=apply(X_pred, 2, quantile, prob=0.025), 
         x1=X_test, y1=apply(X_pred, 2, quantile, prob=0.975), 
         col=adjustcolor("black", alpha.f=0.25))
abline(a=0, b=1, col="red")
abline(lm(apply(X_pred, 2, mean) ~ X_test), col="blue")
summary(lm(apply(X_pred, 2, mean) ~ X_test))

## sort the data to be in the same order as the predictions
plot(pred_mu_WA ~ X_test, ylab="predicted mean", xlab="Observed", 
     main="Cross-validation of WA model", 
     xlim=range(X_test), ylim=c(min(X_test - 2), max(X_test + 2)))
## Notice most of the confidence intervals cover the red linear regression line 
## i.e. the 95% CI is not close to 95%
segments(x0=X_test, y0=pred_mu_WA - 2 * pred_sd_WA,
         x1=X_test, y1=pred_mu_WA + 2 * pred_sd_WA,
         col=adjustcolor("black", alpha.f=0.25))
abline(a=0, b=1, col="red")
abline(lm(pred_mu_WA ~ X_test), col="blue")
summary(lm(pred_mu_WA ~ X_test))

## sort the data to be in the same order as the predictions
plot(pred_mu_MLRC ~ X_test, ylab="predicted mean", xlab="Observed", 
     main="Cross-validation of MLRC model", 
     xlim=range(X_test), ylim=c(min(X_test - 2), max(X_test + 2)))
## Notice most of the confidence intervals cover the red linear regression line 
## i.e. the 95% CI is not close to 95%
segments(x0=X_test, y0=pred_mu_MLRC - 2 * pred_sd_MLRC,
         x1=X_test, y1=pred_mu_MLRC + 2 * pred_sd_MLRC,
         col=adjustcolor("black", alpha.f=0.25))
abline(a=0, b=1, col="red")
abline(lm(pred_mu_MLRC ~ X_test), col="blue")
summary(lm(pred_mu_MLRC ~ X_test))

## sort the data to be in the same order as the predictions
plot(pred_mu_MAT ~ X_test, ylab="predicted mean", xlab="Observed", 
     main="Cross-validation of MAT model", 
     xlim=range(X_test), ylim=c(min(X_test - 2), max(X_test + 2)))
## Notice most of the confidence intervals cover the red linear regression line 
## i.e. the 95% CI is not close to 95%
segments(x0=X_test, y0=pred_mu_MAT - 2 * pred_sd_MAT,
         x1=X_test, y1=pred_mu_MAT + 2 * pred_sd_MAT,
         col=adjustcolor("black", alpha.f=0.25))
abline(a=0, b=1, col="red")
abline(lm(pred_mu_MAT ~ X_test), col="blue")
summary(lm(pred_mu_MAT ~ X_test))

## sort the data to be in the same order as the predictions
plot(apply(preds_rf, 1, mean) ~ X_test, ylab="predicted mean", xlab="Observed", 
     main="Cross-validation of RF model", 
     xlim=range(X_test), ylim=c(min(X_test - 2), max(X_test + 2)))
## Notice most of the confidence intervals cover the red linear regression line 
## i.e. the 95% CI is close to 95%
segments(x0=X_test, y0=apply(preds_rf, 1, quantile, prob=0.025), 
         x1=X_test, y1=apply(preds_rf, 1, quantile, prob=0.975), 
         col=adjustcolor("black", alpha.f=0.25))
abline(a=0, b=1, col="red")
abline(lm(apply(preds_rf, 1, mean) ~ X_test), col="blue")
summary(lm(apply(preds_rf, 1, mean) ~ X_test))

## sort the data to be in the same order as the predictions
plot(apply(X_pred_bummer, 2, mean) ~ X_test, 
     ylab="predicted mean", xlab="Observed", 
     main="Cross-validation of Bummer model", 
     xlim=range(X_test), ylim=c(min(X_test - 2), max(X_test + 2)))
## Notice most of the confidence intervals cover the red linear regression line 
## i.e. the 95% CI is close to 95%
segments(x0=X_test, y0=apply(X_pred_bummer, 2, quantile, prob=0.025), 
         x1=X_test, y1=apply(X_pred_bummer, 2, quantile, prob=0.975), 
         col=adjustcolor("black", alpha.f=0.25))
abline(a=0, b=1, col="red")
abline(lm(apply(X_pred_bummer, 2, mean) ~ X_test), col="blue")
summary(lm(apply(X_pred_bummer, 2, mean) ~ X_test))


# dev.copy(pdf, "cv-plot1.pdf", width=9,height=6)


```


```{r}
N_no_analog <- length(analog_idx)
coverage <- matrix(0, N_no_analog, 6)
MSPE <- matrix(0, N_no_analog, 6)
MAE <- matrix(0, N_no_analog, 6)
CRPS <- matrix(0, N_no_analog, 6)

MSPE[, 1] <- (X_test - apply(X_pred, 2, mean))^2
MSPE[, 2] <- (X_test - apply(X_pred_bummer, 2, mean))^2
MSPE[, 3] <- (X_test - pred_mu_WA)^2
MSPE[, 4] <- (X_test - pred_mu_MLRC)^2
MSPE[, 5] <- (X_test - pred_mu_MAT)^2
MSPE[, 6] <- (X_test - mean(preds_rf))^2

MAE[, 1] <- abs(X_test - apply(X_pred, 2, median))
MAE[, 2] <- abs(X_test - apply(X_pred_bummer, 2, median))
MAE[, 3] <- abs(X_test - pred_mu_WA)
MAE[, 4] <- abs(X_test - pred_mu_MLRC)
MAE[, 5] <- abs(X_test - pred_mu_MAT)
MAE[, 6] <- abs(X_test - median(preds_rf))
    
coverage[, 1] <- 
  (X_test > apply(X_pred, 2, quantile, prob=0.025)) & 
  (X_test < apply(X_pred, 2, quantile, prob=0.975))
coverage[, 2] <- 
  (X_test > apply(X_pred_bummer, 2, quantile, prob=0.025)) &
  (X_test < apply(X_pred_bummer, 2, quantile, prob=0.975))
coverage[, 3] <- 
  (X_test > (pred_mu_WA - 2 * pred_sd_WA)) &
  (X_test < (pred_mu_WA + 2 * pred_sd_WA))
coverage[, 4] <-
  (X_test > (pred_mu_MLRC - 2 * pred_sd_MLRC)) &
  (X_test < (pred_mu_MLRC + 2 * pred_sd_MLRC))
coverage[, 5] <- 
  (X_test > (pred_mu_MAT - 2 * pred_sd_MAT)) &
  (X_test < (pred_mu_MAT + 2 * pred_sd_MAT))
coverage[, 6] <-   
  (X_test > apply(preds_rf, 1, quantile, prob=0.025)) &
  (X_test < apply(preds_rf, 1, quantile, prob=0.975))
  

CRPS[, 1] <- makeCRPS(X_pred, X_test, dim(X_pred)[1])
CRPS[, 2] <- makeCRPS(X_pred_bummer, X_test, dim(X_pred_bummer)[1])
CRPS[, 3] <- MAE[, 3]
CRPS[, 4] <- MAE[, 4]
CRPS[, 5] <- MAE[, 5]
CRPS[, 6] <- makeCRPS(t(preds_rf), X_test, dim(preds_rf)[2])

model_names <- c("MVGP", "Bummer", "WA", "MLRC", "MAT", "RF")
colnames(MSPE) <- c("MVGP", "Bummer", "WA", "MLRC", "MAT", "RF")
colnames(MAE) <- c("MVGP", "Bummer", "WA", "MLRC", "MAT", "RF")
colnames(coverage) <- c("MVGP", "Bummer", "WA", "MLRC", "MAT", "RF")
colnames(CRPS) <- c("MVGP", "Bummer", "WA", "MLRC", "MAT", "RF")
results <- rbind(
  apply(MSPE, 2, mean), apply(MAE, 2, mean),
  apply(coverage, 2, mean), apply(CRPS, 2, mean))
rownames(results) <- c("MSPE", "MAE", "Coverage", "CRPS")
library(xtable)
xtable(results)
```


```{r}
kable(results)
```

```{r}
layout(matrix(1:6, 3, 2))
for (i in 1:6) {
  plot(MAE[, i] ~ apply(predMATDist$dist.n, 1, mean), ylim=c(0, max(MAE)), 
       main=model_names[i])  
  abline(lm(MAE[, i] ~ apply(predMATDist$dist.n, 1, mean)), col="red")
}
```









## Pollen Data

# Load Pollen Data and R code
```{r readData-pollen, echo=FALSE, include=FALSE, eval=TRUE, results='hide'}
dat <- read.csv("~/Google Drive/Bogs-Pollen-Lake Data/Reduced.Taxa.calibration.3.23.17.csv", 
                stringsAsFactors=FALSE, header=TRUE)
N <- length(dat$ACERX[-1])
d <- 16
y <- matrix(c(as.numeric(dat$ACERX[-1]), as.numeric(dat$BETULA[-1]), 
            as.numeric(dat$Sum.Other.Conifer[-1]), as.numeric(dat$LARIXPSEU[-1]), 
            as.numeric(dat$Sum.Other.Deciduous[-1]), as.numeric(dat$FAGUS[-1]), 
            as.numeric(dat$FRAXINUX[-1]), as.numeric(dat$Sum.Other.Herbaceous[-1]), 
            as.numeric(dat$Sum.Prairie.Herbs[-1]), as.numeric(dat$Other[-1]), 
            as.numeric(dat$PICEAX[-1]), as.numeric(dat$PINUSX[-1]), 
            as.numeric(dat$QUERCUS[-1]), as.numeric(dat$TILIA[-1]), 
            as.numeric(dat$TSUGAX[-1]), as.numeric(dat$ULMUS[-1])), N, d)

## Adjust for half counts
y <- ceiling(y)
colnames(y) <- names(dat)[5:20]

X_annual <- as.numeric(dat$tmean_annual[-1])
X <- as.numeric(dat$tmean_07[-1])

mean_X <- mean(X)
sd_X <- sd(X)
X <- (X - mean_X) / sd_X

## transform the data to percentages for use in transfer function models
y_prop <- y
for (i in 1:N) {
  y_prop[i, ] <- y_prop[i, ] / sum(y_prop[i, ])
}

```


```{r, include=FALSE}
pollenPlotData <- data.frame(species=as.factor(rep(colnames(y), each=N)),
                              count=c(as.matrix(y_prop)), 
                              temp=rep(X, times=d))

# png(file="./figures/pollen-plot.png", width=6, height=3,
#     units="in", res=400)
ggplot(pollenPlotData, aes(x=temp, y=count, color=species, group=species)) +
  geom_point(alpha=0.25) + 
  theme(legend.position="none") + ggtitle("Species composition vs. July temp")
# dev.off()
```




## Simulate a "no-analog" situation
```{r}
library(dplyr)
modMATDist <- MAT(as.data.frame(y_prop), X, k=10, lean=FALSE)

mod_dists <- tibble(set = "mod", distance = as.vector(modMATDist$dist.n))

## 0.575 cut-off chosen so the validation set is approximately the same size
## as one of the 12-fold cross-validation sets
analog_idx <- which(apply(modMATDist$dist.n, 1, min)  > 0.08)
# length(analog_idx) ## 14
# 152/12  ## 13

y_train <- y[-analog_idx, ]
y_test <- y[analog_idx, ]
X_train <- X[-analog_idx]
X_test <- X[analog_idx]
y_train_prop <- y_train
for (i in 1:nrow(y_train)) {
  y_train_prop[i, ] <- y_train_prop[i, ] / sum(y_train_prop[i, ])
}
y_test_prop <- y_test
for (i in 1:nrow(y_test)) {
  y_test_prop[i, ] <- y_test_prop[i, ] / sum(y_test_prop[i, ])
}
N_pred <- dim(y_test)[1]


modMATDistTrain <- MAT(as.data.frame(y_train_prop), X_train, k=10, lean=FALSE)
predMATDist <- predict(modMATDistTrain, as.data.frame(y_test_prop),
                       k=10, sse=TRUE, n.boot=1000)
mod_dists <- tibble(set = "mod", distance = as.vector(modMATDistTrain$dist.n))
pred_dists <- tibble(set = "pred", distance = as.vector(predMATDist$dist.n))

MAT_dists <- bind_rows(mod_dists, pred_dists)


MAT_dists_plot <- ggplot(MAT_dists, aes(distance, fill=set)) +
  geom_density(alpha=0.7, adjust=1, colour="grey50") + 
  labs(x="square chord distance") + 
  scale_fill_discrete(name=element_blank(), breaks=c("mod", "pred"),
                      labels=c("Training Set", "Reconstruction Set")) +
  theme_bw() + theme(legend.position = "bottom")
MAT_dists_plot

```


```{r}
analogPlotData <- data.frame(
  species = as.factor(rep(colnames(y), each=length(X_train))),
  Count   = c(as.matrix(y_train_prop)), 
  Wetness = rep(X_train, times=dim(y_train_prop)[2]))

noanalogPlotData <- data.frame(
  species = as.factor(rep(colnames(y), each=length(X_test))),
  Count   = c(as.matrix(y_test_prop)), 
  Wetness = rep(X_test, times=dim(y_test_prop)[2]))

gp1 <- ggplot(analogPlotData, aes(x=Wetness, y=Count, color=species, group=species)) +
  geom_point(alpha=0.25) +
  # geom_line(stat="smooth", method="loess", aes(y=Count, x=Wetness),
  #           alpha=0.5, lwd=1.25) +
  theme(legend.position="none") + ggtitle("Analog Training Data") + 
  labs(x="Water Table Depth", y="Composition") + 
  theme(plot.title=element_text(size=24, face="bold", hjust=0.5)) + 
  theme(axis.text.x = element_text(size = 22), 
        axis.text.y = element_text(size = 22),
        axis.title.x = element_text(size = 22), 
        axis.title.y = element_text(size = 22))
gp2 <- ggplot(noanalogPlotData, 
              aes(x=Wetness, y=Count, color=species, group=species)) +
  geom_point(alpha=0.25) +
  # geom_line(stat="smooth", method="loess", aes(y=Count, x=Wetness),
  #           alpha=0.5, lwd=1.25) +
  theme(legend.position="none") + ggtitle("No Analog Training Data") + 
  labs(x="Water Table Depth", y="Composition") + 
  theme(plot.title=element_text(size=24, face="bold", hjust=0.5)) + 
  theme(axis.text.x = element_text(size = 22), 
        axis.text.y = element_text(size = 22),
        axis.title.x = element_text(size = 22), 
        axis.title.y = element_text(size = 22))
multiplot(gp1, gp2, cols=1)
```


```{r}
y <- as.matrix(y)
# mean_X <- mean(X)
# sd_X <- sd(X)
# X <- (X - mean_X) / sd_X
X_knots <- seq(min(X, na.rm=TRUE)-1.25*sd(X, na.rm=TRUE), 
               max(X, na.rm=TRUE)+1.25*sd(X, na.rm=TRUE), length=n_knots)

params <- list(n_adapt=25000, n_mcmc=50000, n_thin=50, 
               X_knots=X_knots, message=500)

save_directory <- "./mvgp-test/"
save_file <- paste0("dm-pollen-no-analog-appendix.RData")
progress_directory <- "./mvgp-test/"
progress_file <- paste0("mvgp-dm-pollen-no-analog-appendix.txt")
```


```{r}
## Fit no-analog using B-spline model
if (file.exists(paste0(save_directory, save_file))) {
  ## load mcmc
  load(file=paste0(save_directory, save_file))
} else {
  
  ## potentially long running MCMC code
  parallelChains <- function (n_chains) {
    Rcpp::sourceCpp('~/mvgp/mcmc/mcmc-dirichlet-multinomial-mvgp.cpp')
    out <- coda::mcmc(mcmcRcpp(as.matrix(y_train), X_train, as.matrix(y_test), 
                               params, n_chain=n_chains, 
                               file_name=here(progress_directory,
                                              progress_file)))
  }
  
  ## Initalize multicore
  sfInit(parallel=TRUE, cpus=4)
  sfClusterSetupRNG()
  sfExport("y_train", "X_train", "y_test", "params", "progress_directory", 
           "progress_file")
  sfLibrary(coda)
  sfLibrary(here)
  
  ## create temporary progress file  
  file.create(here(progress_directory, progress_file))
  
  ## run MCMC
  out <- sfLapply(1:4, parallelChains)
  
  sfStop()
  
  save(out, file=paste0(save_directory, save_file))
  
  # save(out, file=paste0(save_directory, save_file))
  
  Rhat <- make_gelman_rubin(out)
  png(file=here("mvgp-test", "diagnostics",
                paste0("Rhat-no-analog-appendix-pollen.png")),
      width=6, height=6, units="in", res=400)
  layout(matrix(1:9, 3, 3))
  hist(Rhat[grepl("eta", names(Rhat))], main = "Rhat for eta")
  hist(Rhat[grepl("mu", names(Rhat))], main = "Rhat for mu")
  hist(Rhat[grepl("alpha", names(Rhat))], main = "Rhat for alpha")
  hist(Rhat[grepl("zeta", names(Rhat))], main = "Rhat for zeta")
  hist(Rhat[grepl("tau2", names(Rhat))], main = "Rhat for tau2")
  hist(Rhat[grepl("X", names(Rhat))], main = "Rhat for X")
  hist(Rhat[grepl("xi", names(Rhat))], main = "Rhat for xi")
  hist(Rhat[grepl("phi", names(Rhat))], main = "Rhat for phi")
  hist(Rhat, main="All parameters")
  dev.off()
}
```


```{r}
## extract posterior samples
samples <- convert_to_coda(out)

n_chains <- 4
n_save <- dim(samples[[1]])[1] 
n_samples <- n_save*n_chains

mu_post <- matrix(0, n_samples, d)
eta_star_post <- array(0, dim=c(n_samples, n_knots, d))
zeta_post <-  array(0, dim=c(n_samples, N-N_pred, d))
alpha_post <-  array(0, dim=c(n_samples, N-N_pred, d))
zeta_pred_post <-  array(0, dim=c(n_samples, N_pred, d))
alpha_pred_post <-  array(0, dim=c(n_samples, N_pred, d))
phi_post <- rep(0,  n_samples)
tau2_post <- matrix(0,  n_samples, d)
X_pred <- matrix(0,  n_samples, N_pred)
xi_post <- array(0,  dim=c(n_samples, choose(d, 2)))
R_post <- array(0, dim=c(n_samples, d, d))

for(i in 1:n_chains){
  mu_post[1:n_save + (i-1)*n_save, ] <- out[[i]]$mu
  eta_star_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$eta_star
  zeta_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$zeta
  alpha_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$alpha
  zeta_pred_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$zeta_pred
  alpha_pred_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$alpha_pred
  phi_post[1:n_save + (i-1)*n_save] <- out[[i]]$phi
  tau2_post[1:n_save + (i-1)*n_save, ] <- out[[i]]$tau2
  X_pred[1:n_save + (i-1)*n_save, ] <- out[[i]]$X
  xi_post[1:n_save + (i-1)*n_save, ] <- out[[i]]$xi
  R_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$R
}          
```


```{r}
alpha_post_mean <- apply(alpha_post, c(2, 3), mean)
p_alpha <- alpha_post_mean

for (i in 1:length(X_train)) {
  ## normalize to sum-to-one constraint
  p_alpha[i, ] <- p_alpha[i, ] / sum(p_alpha[i, ])
}

fitPlotData <- data.frame(
  species = as.factor(rep(1:d, each=length(X_train))), 
  count = c(as.matrix(y_train_prop)), 
  depth = rep(X_train, times=d), 
  alpha = c(p_alpha))

g1_post <- ggplot(fitPlotData, aes(x=depth, y=count, color=species, group=species)) + 
  geom_point(alpha=0.25) + theme(legend.position="none") +
  ggtitle("Fitted Response vs. depth") + 
  geom_line(aes(x=depth, y=alpha, col = species), fitPlotData, lwd=1.25)

g2_post <- ggplot(fitPlotData, aes(x=depth, y=count, color=species, group=species)) + 
  geom_point(alpha=0.25) + theme(legend.position="none") +
  ggtitle("Fitted Response vs. depth by species") + 
  geom_line(aes(x=depth, y=alpha, col = species), fitPlotData, lwd=1.25) + 
  facet_wrap( ~ species, ncol = 4)
multiplot(g1_post, g2_post, cols=2)
```



```{r, message=FALSE, include=FALSE}

if (file.exists(paste0(save_directory, "other-models-no-analog-pollen-appendix.RData"))) {
  load(file=paste0(save_directory, "other-models-no-analog-pollen-appendix.RData"))
} else {
  y_test_prop <- as.data.frame(y_test_prop)
  y_train_prop <- as.data.frame(y_train_prop)

  ## WA reconstruction - subset to deal with all zero occurrence species
  zeros_idx <- which(apply(y_train_prop, 2, sum) == 0)
  if (length(zeros_idx) > 0) {
    modWA <- rioja::WA(y_train_prop[, - zeros_idx], X_train)
    predWA <- predict(modWA, y_test_prop[, - zeros_idx], sse=TRUE, nboot=1000)
  } else {
    ## no data to subset
    modWA <- rioja::WA(y_train_prop, X_train)
    predWA <- predict(modWA, y_test_prop, sse=TRUE, nboot=1000)      
  }
  
  pred_mu_WA <- predWA$fit[, 1]
  pred_sd_WA <- sqrt(predWA$v1.boot[, 1]^2 + predWA$v2.boot[1]^2)
  
  ## MLRC reconstruction - subset to deal with all zero occurrence species
  zeros_idx <- which(apply(y_train_prop, 2, sum) == 0)
  if (length(zeros_idx) > 0) {
    modMLRC <- rioja::MLRC(y_train_prop[, - zeros_idx], X_train)
    predMLRC <- predict(modMLRC, y_test_prop[, - zeros_idx],
                        sse=TRUE, nboot=1000)
  } else {
    modMLRC <- rioja::MLRC(y_train_prop, X_train)
    predMLRC <- predict(modMLRC, y_test_prop, sse=TRUE, nboot=1000)
  }
  
  pred_mu_MLRC <- predMLRC$fit[, 1]
  pred_sd_MLRC <- sqrt(predMLRC$v1.boot[, 1]^2 + predMLRC$v2.boot[1]^2)
  
  ## Modern analogue technique
  modMAT <- MAT(y_train_prop, X_train, k=20, lean=FALSE)
  predMAT <- predict(modMAT, y_test_prop, k=10, sse=TRUE, n.boot=1000)
  
  pred_mu_MAT <- predMAT$fit.boot[, 2]
  pred_sd_MAT <- sqrt(predMAT$v1.boot[, 2]^2+ predMAT$v2.boot[2])
  
  ## Random Forest
  library(randomForest)
  train <- data.frame(y=X_train, as.matrix(y_train_prop))
  test <- data.frame(as.matrix(y_test_prop))
  n_samples <- 2000
  rf <- randomForest(y ~ ., data = train, ntree=n_samples)
  preds_rf <- predict(rf, test, predict.all=TRUE)$individual

  save(pred_mu_WA, pred_sd_WA, pred_mu_MLRC, pred_sd_MLRC, 
       pred_mu_MAT, pred_sd_MAT, preds_rf, 
       file= paste0(save_directory, "other-models-no-analog-pollen-appendix.RData"))
}
```
  
  
  
# Fit stan model
# Fit model

```{r stan-model-pollen}
## unload snow and snowfall packages as they confilct with STAN
detach_package <- function(pkg, character.only = FALSE)
{
  if(!character.only)
  {
    pkg <- deparse(substitute(pkg))
  }
  search_item <- paste("package", pkg, sep = ":")
  while(search_item %in% search())
  {
    detach(search_item, unload = TRUE, character.only = TRUE)
  }
}
detach_package(snowfall)
detach_package(snow)
## check if snow and snowfall packages are loaded
(.packages())

# mu_X <- mean(X)
# sd_X <- sd(X)
# X_center <- (X_train-mu_X) / sd_X
X_center <- X[-analog_idx]
if (file.exists(paste0(save_directory, "bummer-no-analog-pollen-appendix.RData"))) {
  ## Load MCMC run
  load(paste0(save_directory, "bummer-no-analog-pollen-appendix.RData"))
} else {
  ## Long running MCMC
  library(rstan)
  n_mcmc <- 500
  rstan_options(auto_write = TRUE)
  options(mc.cores = parallel::detectCores())
  
  dat=list(N=length(X_train), d=dim(y_train)[2], X=X_train, 
           y=as.matrix(y_train, length(X_train), dim(y_train)[2]))
  
  init_fun <- function() { list(
    a=runif(d, 1, 10),
    mu=rnorm(d, 0, 1),
    sigma2=runif(d, 1, 5),
    alpha=matrix(runif(N*d, 1, 5), N, d)) }
  
  fit = stan(file="~/BayesComposition/bummer-dm.stan", iter=n_mcmc,
             verbose=FALSE, data=dat, chains=4, init=init_fun,
             control=list(adapt_delta=0.99, stepsize=0.01, max_treedepth=15))
  save(fit, file=paste0(save_directory, "bummer-no-analog-pollen-appendix.RData"))
}
```

### predict using stan model

```{r}

X_pred_bummer <- c()
if (file.exists(paste0(save_directory, "bummer-no-analog-predictions-pollen-appendix.RData"))) {
  load(file=paste0(save_directory, "bummer-no-analog-predictions-pollen-appendix.RData"))
} else {
  ## load the data
  load(paste0(save_directory, "bummer-no-analog-pollen-appendix.RData"))
  ## extract samples
  e = rstan::extract(fit, permuted = TRUE)
  
  ddirmult <- function(yy, alpha, log=TRUE) {
    yy <- as.numeric(yy)
    sum_y <- sum(yy)
    if (log) {
      return(lgamma(apply(alpha, 1, sum)) -
               lgamma(sum_y + apply(alpha, 1, sum)) +
               apply(lgamma(t(yy + t(alpha))), 1, sum) - 
               apply(lgamma(alpha), 1, sum))
    } else {
      return(exp(lgamma(apply(alpha, 1, sum)) - 
                   lgamma(sum_y + apply(alpha, 1, sum)) +
                   apply(lgamma(t(yy + t(alpha))), 1, sum) - 
                   apply(lgamma(alpha), 1, sum)))      
    }
  }
  n_iter <- dim(e$a)[1]
  n_grid <- 500
  N_pred <- dim(y_test)[1]
  XX_post <- matrix(0, n_iter, N_pred)
  X_grid <- seq(from=min(X_center) - 1.25*sd(X_center), 
                to=max(X_center) + 1.25*sd(X_center), length=n_grid)
  alpha_pred <- array(0, dim=c(n_iter, n_grid, d))
  
  for (k in 1:n_iter) {
    if (k %% 50 == 0) {
      message("Iteration ", k, " out of ", n_iter)
    }
    for (ii in 1:n_grid) {
      alpha_pred[k, ii, ] <- e$a[k, ] * exp( - (e$mu[k, ] - X_grid[ii])^2 / e$sigma2[k, ])
    }
    for (ii in 1:N_pred) {
      tmp <- ddirmult(y_test[ii, ], alpha_pred[k, , ], log=TRUE)
      ## correct for numeric overflow
      ## doesn't change anything because we divide by the correction factor
      pis <- exp(tmp - max(tmp)) * dnorm(X_grid, 0, 1)
      pis <- pis / sum(pis)
      XX_post[k, ii] <- sample(X_grid, size=1, replace=FALSE, prob=pis)
    }
  }
  
  ## convert to original scale
  # XX_post <- XX_post * sd_X + mu_X
  X_pred_bummer <- XX_post
  save(X_pred_bummer,
       file=paste0(save_directory, "bummer-no-analog-predictions-pollen-appendix.RData"))
}
```


## Plot results

```{r} 
layout(matrix(1:6, 2, 3))
## sort the data to be in the same order as the predictions
plot(apply(X_pred, 2, mean) ~ X_test, ylab="predicted mean", xlab="Observed", 
     main="Cross-validation of MVGP model", 
     xlim=range(X_test), ylim=c(min(X_test - 2), max(X_test + 2)))
## Notice most of the confidence intervals cover the red linear regression line 
## i.e. the 95% CI is close to 95%
segments(x0=X_test, y0=apply(X_pred, 2, quantile, prob=0.025), 
         x1=X_test, y1=apply(X_pred, 2, quantile, prob=0.975), 
         col=adjustcolor("black", alpha.f=0.25))
abline(a=0, b=1, col="red")
abline(lm(apply(X_pred, 2, mean) ~ X_test), col="blue")
summary(lm(apply(X_pred, 2, mean) ~ X_test))

## sort the data to be in the same order as the predictions
plot(pred_mu_WA ~ X_test, ylab="predicted mean", xlab="Observed", 
     main="Cross-validation of WA model", 
     xlim=range(X_test), ylim=c(min(X_test - 2), max(X_test + 2)))
## Notice most of the confidence intervals cover the red linear regression line 
## i.e. the 95% CI is not close to 95%
segments(x0=X_test, y0=pred_mu_WA - 2 * pred_sd_WA,
         x1=X_test, y1=pred_mu_WA + 2 * pred_sd_WA,
         col=adjustcolor("black", alpha.f=0.25))
abline(a=0, b=1, col="red")
abline(lm(pred_mu_WA ~ X_test), col="blue")
summary(lm(pred_mu_WA ~ X_test))

## sort the data to be in the same order as the predictions
plot(pred_mu_MLRC ~ X_test, ylab="predicted mean", xlab="Observed", 
     main="Cross-validation of MLRC model", 
     xlim=range(X_test), ylim=c(min(X_test - 2), max(X_test + 2)))
## Notice most of the confidence intervals cover the red linear regression line 
## i.e. the 95% CI is not close to 95%
segments(x0=X_test, y0=pred_mu_MLRC - 2 * pred_sd_MLRC,
         x1=X_test, y1=pred_mu_MLRC + 2 * pred_sd_MLRC,
         col=adjustcolor("black", alpha.f=0.25))
abline(a=0, b=1, col="red")
abline(lm(pred_mu_MLRC ~ X_test), col="blue")
summary(lm(pred_mu_MLRC ~ X_test))

## sort the data to be in the same order as the predictions
plot(pred_mu_MAT ~ X_test, ylab="predicted mean", xlab="Observed", 
     main="Cross-validation of MAT model", 
     xlim=range(X_test), ylim=c(min(X_test - 2), max(X_test + 2)))
## Notice most of the confidence intervals cover the red linear regression line 
## i.e. the 95% CI is not close to 95%
segments(x0=X_test, y0=pred_mu_MAT - 2 * pred_sd_MAT,
         x1=X_test, y1=pred_mu_MAT + 2 * pred_sd_MAT,
         col=adjustcolor("black", alpha.f=0.25))
abline(a=0, b=1, col="red")
abline(lm(pred_mu_MAT ~ X_test), col="blue")
summary(lm(pred_mu_MAT ~ X_test))

## sort the data to be in the same order as the predictions
plot(apply(preds_rf, 1, mean) ~ X_test, ylab="predicted mean", xlab="Observed", 
     main="Cross-validation of RF model", 
     xlim=range(X_test), ylim=c(min(X_test - 2), max(X_test + 2)))
## Notice most of the confidence intervals cover the red linear regression line 
## i.e. the 95% CI is close to 95%
segments(x0=X_test, y0=apply(preds_rf, 1, quantile, prob=0.025), 
         x1=X_test, y1=apply(preds_rf, 1, quantile, prob=0.975), 
         col=adjustcolor("black", alpha.f=0.25))
abline(a=0, b=1, col="red")
abline(lm(apply(preds_rf, 1, mean) ~ X_test), col="blue")
summary(lm(apply(preds_rf, 1, mean) ~ X_test))

## sort the data to be in the same order as the predictions
plot(apply(X_pred_bummer, 2, mean) ~ X_test, 
     ylab="predicted mean", xlab="Observed", 
     main="Cross-validation of Bummer model", 
     xlim=range(X_test), ylim=c(min(X_test - 2), max(X_test + 2)))
## Notice most of the confidence intervals cover the red linear regression line 
## i.e. the 95% CI is close to 95%
segments(x0=X_test, y0=apply(X_pred_bummer, 2, quantile, prob=0.025), 
         x1=X_test, y1=apply(X_pred_bummer, 2, quantile, prob=0.975), 
         col=adjustcolor("black", alpha.f=0.25))
abline(a=0, b=1, col="red")
abline(lm(apply(X_pred_bummer, 2, mean) ~ X_test), col="blue")
summary(lm(apply(X_pred_bummer, 2, mean) ~ X_test))


# dev.copy(pdf, "cv-plot1.pdf", width=9,height=6)


```


```{r}
N_no_analog <- length(analog_idx)
coverage <- matrix(0, N_no_analog, 6)
MSPE <- matrix(0, N_no_analog, 6)
MAE <- matrix(0, N_no_analog, 6)
CRPS <- matrix(0, N_no_analog, 6)

MSPE[, 1] <- (X_test - apply(X_pred, 2, mean))^2
MSPE[, 2] <- (X_test - apply(X_pred_bummer, 2, mean))^2
MSPE[, 3] <- (X_test - pred_mu_WA)^2
MSPE[, 4] <- (X_test - pred_mu_MLRC)^2
MSPE[, 5] <- (X_test - pred_mu_MAT)^2
MSPE[, 6] <- (X_test - mean(preds_rf))^2

MAE[, 1] <- abs(X_test - apply(X_pred, 2, median))
MAE[, 2] <- abs(X_test - apply(X_pred_bummer, 2, median))
MAE[, 3] <- abs(X_test - pred_mu_WA)
MAE[, 4] <- abs(X_test - pred_mu_MLRC)
MAE[, 5] <- abs(X_test - pred_mu_MAT)
MAE[, 6] <- abs(X_test - median(preds_rf))
    
coverage[, 1] <- 
  (X_test > apply(X_pred, 2, quantile, prob=0.025)) & 
  (X_test < apply(X_pred, 2, quantile, prob=0.975))
coverage[, 2] <- 
  (X_test > apply(X_pred_bummer, 2, quantile, prob=0.025)) &
  (X_test < apply(X_pred_bummer, 2, quantile, prob=0.975))
coverage[, 3] <- 
  (X_test > (pred_mu_WA - 2 * pred_sd_WA)) &
  (X_test < (pred_mu_WA + 2 * pred_sd_WA))
coverage[, 4] <-
  (X_test > (pred_mu_MLRC - 2 * pred_sd_MLRC)) &
  (X_test < (pred_mu_MLRC + 2 * pred_sd_MLRC))
coverage[, 5] <- 
  (X_test > (pred_mu_MAT - 2 * pred_sd_MAT)) &
  (X_test < (pred_mu_MAT + 2 * pred_sd_MAT))
coverage[, 6] <-   
  (X_test > apply(preds_rf, 1, quantile, prob=0.025)) &
  (X_test < apply(preds_rf, 1, quantile, prob=0.975))
  

CRPS[, 1] <- makeCRPS(X_pred, X_test, dim(X_pred)[1])
CRPS[, 2] <- makeCRPS(X_pred_bummer, X_test, dim(X_pred_bummer)[1])
CRPS[, 3] <- MAE[, 3]
CRPS[, 4] <- MAE[, 4]
CRPS[, 5] <- MAE[, 5]
CRPS[, 6] <- makeCRPS(t(preds_rf), X_test, dim(preds_rf)[2])

model_names <- c("MVGP", "Bummer", "WA", "MLRC", "MAT", "RF")
colnames(MSPE) <- c("MVGP", "Bummer", "WA", "MLRC", "MAT", "RF")
colnames(MAE) <- c("MVGP", "Bummer", "WA", "MLRC", "MAT", "RF")
colnames(coverage) <- c("MVGP", "Bummer", "WA", "MLRC", "MAT", "RF")
colnames(CRPS) <- c("MVGP", "Bummer", "WA", "MLRC", "MAT", "RF")
results <- rbind(
  apply(MSPE, 2, mean), apply(MAE, 2, mean),
  apply(coverage, 2, mean), apply(CRPS, 2, mean))
rownames(results) <- c("MSPE", "MAE", "Coverage", "CRPS")
library(xtable)
xtable(results)
```


```{r}
kable(results)
```

```{r}
layout(matrix(1:6, 3, 2))
for (i in 1:6) {
  plot(MAE[, i] ~ apply(predMATDist$dist.n, 1, mean), ylim=c(0, max(MAE)), 
       main=model_names[i])  
  abline(lm(MAE[, i] ~ apply(predMATDist$dist.n, 1, mean)), col="red")
}
```
